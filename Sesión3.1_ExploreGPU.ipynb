{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCUDA basics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%install_ext http://raw.github.com/jrjohansson/version_information/master/version_information.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#to install, execute in a cell: \n",
    "%install_ext https://raw.github.com/minrk/ipython_extensions/master/nbtoc.py\n",
    "%load_ext nbtoc\n",
    "%nbtoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "2.7.6 64bit [GCC 4.8.2]"
        },
        {
         "module": "IPython",
         "version": "5.1.0"
        },
        {
         "module": "OS",
         "version": "Linux 3.19.0 59 generic x86_64 with Ubuntu 14.04 trusty"
        },
        {
         "module": "numpy",
         "version": "1.11.1"
        },
        {
         "module": "scipy",
         "version": "0.17.1"
        },
        {
         "module": "matplotlib",
         "version": "2.0.0b3+2000.g22aa800"
        },
        {
         "module": "sympy",
         "version": "1.0"
        },
        {
         "module": "pycuda",
         "version": "2016.1"
        },
        {
         "module": "pycula",
         "version": "The 'pycula' distribution was not found and is required by the application"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>2.7.6 64bit [GCC 4.8.2]</td></tr><tr><td>IPython</td><td>5.1.0</td></tr><tr><td>OS</td><td>Linux 3.19.0 59 generic x86_64 with Ubuntu 14.04 trusty</td></tr><tr><td>numpy</td><td>1.11.1</td></tr><tr><td>scipy</td><td>0.17.1</td></tr><tr><td>matplotlib</td><td>2.0.0b3+2000.g22aa800</td></tr><tr><td>sympy</td><td>1.0</td></tr><tr><td>pycuda</td><td>2016.1</td></tr><tr><td>pycula</td><td>The 'pycula' distribution was not found and is required by the application</td></tr><tr><td colspan='2'>Wed Sep 21 11:23:34 2016 CDT</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 2.7.6 64bit [GCC 4.8.2] \\\\ \\hline\n",
       "IPython & 5.1.0 \\\\ \\hline\n",
       "OS & Linux 3.19.0 59 generic x86\\_64 with Ubuntu 14.04 trusty \\\\ \\hline\n",
       "numpy & 1.11.1 \\\\ \\hline\n",
       "scipy & 0.17.1 \\\\ \\hline\n",
       "matplotlib & 2.0.0b3+2000.g22aa800 \\\\ \\hline\n",
       "sympy & 1.0 \\\\ \\hline\n",
       "pycuda & 2016.1 \\\\ \\hline\n",
       "pycula & The 'pycula' distribution was not found and is required by the application \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Wed Sep 21 11:23:34 2016 CDT} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 2.7.6 64bit [GCC 4.8.2]\n",
       "IPython 5.1.0\n",
       "OS Linux 3.19.0 59 generic x86_64 with Ubuntu 14.04 trusty\n",
       "numpy 1.11.1\n",
       "scipy 0.17.1\n",
       "matplotlib 2.0.0b3+2000.g22aa800\n",
       "sympy 1.0\n",
       "pycuda 2016.1\n",
       "pycula The 'pycula' distribution was not found and is required by the application\n",
       "Wed Sep 21 11:23:34 2016 CDT"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, scipy, matplotlib, sympy, pycuda, pycula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pycuda\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_Simple\t\t\t __pycache__\r\n",
      "2013-12-03-Crank_Nicolson.ipynb  pycuda-helpers.hpp\r\n",
      "addCPU\t\t\t\t README.md\r\n",
      "Animation.ipynb\t\t\t README.md~\r\n",
      "BuildTesting.ipynb\t\t SchrodingerBOX.pdf\r\n",
      "cpua\t\t\t\t Sesion1_Introduccion_Python.ipynb\r\n",
      "cpuAdd.c\t\t\t Sesion1_Test.ipynb\r\n",
      "cpuAdd.c~\t\t\t Sesion2_Intento_de_solucion_GPE.ipynb\r\n",
      "CUDAkernelsCONS.cu\t\t Sesión3.1_ExploreGPU.ipynb\r\n",
      "CUDAkernelsCONS.cu~\t\t Sesion3_CUDA&PyCuda1st.ipynb\r\n",
      "CUDAkernels.cu\t\t\t Sesion4_PyCUDA_2nd.ipynb\r\n",
      "CUDAkernels.cu~\t\t\t Sesion5.5_MemoriasCUDA.ipynb\r\n",
      "CUDATools.py\t\t\t Sesion5_MemoriasCUDA.ipynb\r\n",
      "CUDATools.pyc\t\t\t Sesion6_PDE_CUDA_670.ipynb\r\n",
      "ExploringLayeredMemory.ipynb\t Sesion6_PDE_CUDA_780.ipynb\r\n",
      "gpu\t\t\t\t Sesion6_PDE_CUDA.ipynb\r\n",
      "gpuAdd\t\t\t\t Sesion6_PDE_CUDA-Tesla.ipynb\r\n",
      "gpuAdd.cu\t\t\t Sesion7_Librerias(FFT) GTX 780.ipynb\r\n",
      "gpuAdd.cu~\t\t\t Sesion7_Librerias(FFT)-Tesla C2075.ipynb\r\n",
      "imagen\t\t\t\t Sesion8_PDE_CUDA_Schrodinger.ipynb\r\n",
      "intervalo.py\t\t\t Some_bench.ipynb\r\n",
      "intervalo.pyc\t\t\t taylor.py\r\n",
      "libpeerconnection.log\t\t taylor.py~\r\n",
      "License.txt\t\t\t taylor.pyc\r\n",
      "Longuet-Higgins.ipynb\t\t testingCUDA.py\r\n",
      "MeshingXYZ.ipynb\t\t TestinImplSurfTexPyCUDA.ipynb\r\n",
      "MYpycuda-helpers.hpp\t\t Untitled.ipynb\r\n",
      "N-Body.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# Comandos de bash\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la rama master\r\n",
      "Su rama está delante de «origin/master» para 1 commit.\r\n",
      "  (use \"git push\" to publish your local commits)\r\n",
      "Cambios no preparados para el commit:\r\n",
      "  (use «git add/rm <archivo>...» para actualizar lo que se confirmará)\r\n",
      "  (use «git checkout -- <archivo>...» para descartar cambios en el directorio de trabajo)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   Sesion1_Introduccion_Python.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   Sesion5_MemoriasCUDA.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   Sesion6_PDE_CUDA.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   Sesion6_PDE_CUDA_780.ipynb\u001b[m\r\n",
      "\t\u001b[31mdeleted:    Sesion7_LibreriasGPU.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   \"Sesi\\303\\263n3.1_ExploreGPU.ipynb\"\u001b[m\r\n",
      "\r\n",
      "Archivos sin seguimiento:\r\n",
      "  (use «git add <archivo>...» para incluir en lo que se ha de confirmar)\r\n",
      "\r\n",
      "\t\u001b[31m2013-12-03-Crank_Nicolson.ipynb\u001b[m\r\n",
      "\t\u001b[31mBuildTesting.ipynb\u001b[m\r\n",
      "\t\u001b[31mCUDATools.py\u001b[m\r\n",
      "\t\u001b[31mCUDATools.pyc\u001b[m\r\n",
      "\t\u001b[31mCUDAkernelsCONS.cu\u001b[m\r\n",
      "\t\u001b[31mCUDAkernelsCONS.cu~\u001b[m\r\n",
      "\t\u001b[31mExploringLayeredMemory.ipynb\u001b[m\r\n",
      "\t\u001b[31mMYpycuda-helpers.hpp\u001b[m\r\n",
      "\t\u001b[31mMeshingXYZ.ipynb\u001b[m\r\n",
      "\t\u001b[31mSesion5.5_MemoriasCUDA.ipynb\u001b[m\r\n",
      "\t\u001b[31mSesion6_PDE_CUDA-Tesla.ipynb\u001b[m\r\n",
      "\t\u001b[31mSesion6_PDE_CUDA_670.ipynb\u001b[m\r\n",
      "\t\u001b[31mSesion7_Librerias(FFT) GTX 780.ipynb\u001b[m\r\n",
      "\t\u001b[31mSesion7_Librerias(FFT)-Tesla C2075.ipynb\u001b[m\r\n",
      "\t\u001b[31mSesion8_PDE_CUDA_Schrodinger.ipynb\u001b[m\r\n",
      "\t\u001b[31mTestinImplSurfTexPyCUDA.ipynb\u001b[m\r\n",
      "\t\u001b[31mUntitled.ipynb\u001b[m\r\n",
      "\t\u001b[31m__pycache__/\u001b[m\r\n",
      "\t\u001b[31mlibpeerconnection.log\u001b[m\r\n",
      "\t\u001b[31mpycuda-helpers.hpp\u001b[m\r\n",
      "\t\u001b[31mtestingCUDA.py\u001b[m\r\n",
      "\r\n",
      "no hay cambios agregados al commit (use «git add» o «git commit -a»)\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2015 NVIDIA Corporation\r\n",
      "Built on Tue_Aug_11_14:27:32_CDT_2015\r\n",
      "Cuda compilation tools, release 7.5, V7.5.17\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring your GPU device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pycuda import autoinit\n",
    "from pycuda.tools import DeviceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "specs = DeviceData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max threads per block =  1024\n"
     ]
    }
   ],
   "source": [
    "print 'Max threads per block = ',specs.max_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp size            = 32\n",
      "Warps per MP         = 48\n",
      "Thread Blocks per MP = 8\n",
      "Registers            = 65536\n",
      "Shared memory        = 49152\n",
      "Granularity ??       = 32\n"
     ]
    }
   ],
   "source": [
    "print 'Warp size            =', specs.warp_size\n",
    "print 'Warps per MP         =', specs.warps_per_mp\n",
    "print 'Thread Blocks per MP =', specs.thread_blocks_per_mp\n",
    "print 'Registers            =', specs.registers\n",
    "print 'Shared memory        =', specs.shared_memory\n",
    "print 'Granularity ??       =', specs.smem_granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GTX 670\n",
    "    Warp size            = 32\n",
    "    Warps per MP         = 48\n",
    "    Thread Blocks per MP = 8\n",
    "    Registers            = 65536\n",
    "    Shared memory        = 49152\n",
    "    Granularity ??       = 32\n",
    "\n",
    "    GTX 860m\n",
    "    Warp size            = 32\n",
    "    Warps per MP         = 48\n",
    "    Thread Blocks per MP = 8\n",
    "    Registers            = 65536\n",
    "    Shared memory        = 49152\n",
    "    Granularity ??       = 32\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pycuda.driver as drv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drv.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 5, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drv.get_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localized GPUs = 1\n"
     ]
    }
   ],
   "source": [
    "devn = drv.Device.count()\n",
    "print 'Localized GPUs =',devn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "devices = []\n",
    "for i in range(devn):\n",
    "    devices.append(drv.Device(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All you want to know about your GPU, but you're afraid to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name =  GeForce GTX 860M\n",
      "PCI Bus =  0000:01:00.0\n",
      "Compute Capability =  (5, 0)\n",
      "Total Memory =  2047.875 MBytes\n",
      "(pycuda._driver.device_attribute.MAX_THREADS_PER_BLOCK, 1024)\n",
      "(pycuda._driver.device_attribute.MAX_BLOCK_DIM_X, 1024)\n",
      "(pycuda._driver.device_attribute.MAX_BLOCK_DIM_Y, 1024)\n",
      "(pycuda._driver.device_attribute.MAX_BLOCK_DIM_Z, 64)\n",
      "(pycuda._driver.device_attribute.MAX_GRID_DIM_X, 2147483647)\n",
      "(pycuda._driver.device_attribute.MAX_GRID_DIM_Y, 65535)\n",
      "(pycuda._driver.device_attribute.MAX_GRID_DIM_Z, 65535)\n",
      "(pycuda._driver.device_attribute.MAX_SHARED_MEMORY_PER_BLOCK, 49152)\n",
      "(pycuda._driver.device_attribute.TOTAL_CONSTANT_MEMORY, 65536)\n",
      "(pycuda._driver.device_attribute.WARP_SIZE, 32)\n",
      "(pycuda._driver.device_attribute.MAX_PITCH, 2147483647)\n",
      "(pycuda._driver.device_attribute.MAX_REGISTERS_PER_BLOCK, 65536)\n",
      "(pycuda._driver.device_attribute.CLOCK_RATE, 1019500)\n",
      "(pycuda._driver.device_attribute.TEXTURE_ALIGNMENT, 512)\n",
      "(pycuda._driver.device_attribute.GPU_OVERLAP, 1)\n",
      "(pycuda._driver.device_attribute.MULTIPROCESSOR_COUNT, 5)\n",
      "(pycuda._driver.device_attribute.KERNEL_EXEC_TIMEOUT, 1)\n",
      "(pycuda._driver.device_attribute.INTEGRATED, 0)\n",
      "(pycuda._driver.device_attribute.CAN_MAP_HOST_MEMORY, 1)\n",
      "(pycuda._driver.device_attribute.COMPUTE_MODE, pycuda._driver.compute_mode.DEFAULT)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_WIDTH, 65536)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_WIDTH, 65536)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_HEIGHT, 65536)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_WIDTH, 4096)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_HEIGHT, 4096)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_DEPTH, 4096)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_WIDTH, 16384)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_HEIGHT, 16384)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES, 2048)\n",
      "(pycuda._driver.device_attribute.SURFACE_ALIGNMENT, 512)\n",
      "(pycuda._driver.device_attribute.CONCURRENT_KERNELS, 1)\n",
      "(pycuda._driver.device_attribute.ECC_ENABLED, 0)\n",
      "(pycuda._driver.device_attribute.PCI_BUS_ID, 1)\n",
      "(pycuda._driver.device_attribute.PCI_DEVICE_ID, 0)\n",
      "(pycuda._driver.device_attribute.TCC_DRIVER, 0)\n",
      "(pycuda._driver.device_attribute.MEMORY_CLOCK_RATE, 2505000)\n",
      "(pycuda._driver.device_attribute.GLOBAL_MEMORY_BUS_WIDTH, 128)\n",
      "(pycuda._driver.device_attribute.L2_CACHE_SIZE, 2097152)\n",
      "(pycuda._driver.device_attribute.MAX_THREADS_PER_MULTIPROCESSOR, 2048)\n",
      "(pycuda._driver.device_attribute.ASYNC_ENGINE_COUNT, 1)\n",
      "(pycuda._driver.device_attribute.UNIFIED_ADDRESSING, 1)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LAYERED_WIDTH, 16384)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LAYERED_LAYERS, 2048)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_GATHER_WIDTH, 16384)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_GATHER_HEIGHT, 16384)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE, 2048)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE, 2048)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE, 16384)\n",
      "(pycuda._driver.device_attribute.PCI_DOMAIN_ID, 0)\n",
      "(pycuda._driver.device_attribute.TEXTURE_PITCH_ALIGNMENT, 32)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_WIDTH, 16384)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH, 16384)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS, 2046)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_WIDTH, 65536)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_WIDTH, 65536)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_HEIGHT, 32768)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_WIDTH, 65536)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_HEIGHT, 32768)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_DEPTH, 2048)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_LAYERED_WIDTH, 65536)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_LAYERED_LAYERS, 2048)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_WIDTH, 65536)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_HEIGHT, 32768)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_LAYERS, 2048)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_WIDTH, 32768)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH, 32768)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS, 2046)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LINEAR_WIDTH, 134217728)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_WIDTH, 65000)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_HEIGHT, 65000)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_PITCH, 1048544)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH, 16384)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT, 16384)\n",
      "(pycuda._driver.device_attribute.COMPUTE_CAPABILITY_MAJOR, 5)\n",
      "(pycuda._driver.device_attribute.COMPUTE_CAPABILITY_MINOR, 0)\n",
      "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH, 16384)\n",
      "(pycuda._driver.device_attribute.STREAM_PRIORITIES_SUPPORTED, 1)\n",
      "(pycuda._driver.device_attribute.GLOBAL_L1_CACHE_SUPPORTED, 0)\n",
      "(pycuda._driver.device_attribute.LOCAL_L1_CACHE_SUPPORTED, 1)\n",
      "(pycuda._driver.device_attribute.MAX_SHARED_MEMORY_PER_MULTIPROCESSOR, 65536)\n",
      "(pycuda._driver.device_attribute.MAX_REGISTERS_PER_MULTIPROCESSOR, 65536)\n",
      "(pycuda._driver.device_attribute.MANAGED_MEMORY, 1)\n",
      "(pycuda._driver.device_attribute.MULTI_GPU_BOARD, 0)\n",
      "(pycuda._driver.device_attribute.MULTI_GPU_BOARD_GROUP_ID, 0)\n",
      "------------------\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "for sp in devices:\n",
    "    print 'Name = ',sp.name()\n",
    "    print 'PCI Bus = ',sp.pci_bus_id()\n",
    "    print 'Compute Capability = ',sp.compute_capability()\n",
    "    print 'Total Memory = ',sp.total_memory()/(2.**20) , 'MBytes'\n",
    "    attr = sp.get_attributes()\n",
    "    for j in range(len(attr.items())):\n",
    "        print attr.items()[j]#,'Bytes (when apply)'\n",
    "    print '------------------'\n",
    "    print '------------------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAX_THREADS_PER_BLOCK, 1024\n",
    "\n",
    "For example for a 3D mesh (less optimal), we only have avaiable $$8\\times 8\\times 8 = 512 \\,simetric$$ \n",
    " $$8\\times 8\\times 16 = 1024 \\,cilindrical$$\n",
    "block size per dimension = 8 or 16.\n",
    "In 2D case the optimal value is:\n",
    "$$32\\times32 = 1024$$\n",
    "In last case $$1024$$\n",
    "\n",
    "\n",
    "MAX_THREADS_PER_MULTIPROCESSOR, $1536 = 3*2^9$\n",
    "\n",
    "If we can take this literally, we can process in one processor about 3 meshes of $8\\times8\\times8$, or three blocks of 3D meshes. With this result, we can evaluate the eficience comparing cilindrical and simetric performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now your device has .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2006.47265625, 'MB of Free Memory', 2047.875, 'MB Total Memory')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drv.mem_get_info()[0]/(2.**20),'MB of Free Memory',drv.mem_get_info()[1]/(2.**20),'MB Total Memory'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think in array sizes. For example a float of 4 bytes length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear max length: 525984768\n",
      "2D max length    : 22934.3578066\n",
      "3D max length    : 807.218405712\n"
     ]
    }
   ],
   "source": [
    "print 'Linear max length:', drv.mem_get_info()[0]/(4)\n",
    "print '2D max length    :', np.sqrt(drv.mem_get_info()[0]/(4))\n",
    "print '3D max length    :', np.power(drv.mem_get_info()[0]/(4),1./3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 21 11:28:21 2016       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 361.45.18              Driver Version: 361.45.18                 |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 860M    Off  | 0000:01:00.0     Off |                  N/A |\r\n",
      "| N/A   43C    P8    N/A /  N/A |     41MiB /  2047MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      9322    G   Xorg                                             4MiB |\r\n",
      "|    0      9432    C   /usr/bin/python                                 27MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
