{
 "metadata": {
  "name": "",
  "signature": "sha256:2184a7a03feaafb67a77d4ad64d3bf0a43d8dce45987539be39b0129fc72103c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "__CUDA__ __C__  _#_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://docs.nvidia.com/cuda\"><img src=\"imagen/CUDA.png\" width=\"30%\" /></a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ejemplo b\u00e1sico: Suma de vectores."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      ">Recordemos como se ve un programa de C. Posteriormente el entorno puro de CUDA C.\n",
      "Como veremos a continuacion realmente programar la targeta grafica se reduce en primera instancia a tener un codigo en C# y agregar sobre este funciones de propias de CUDA (o *kernels*). Estas funciones o _kernels_ son ejecutados en la GPU de forma paralela.\n",
      "\n",
      ">En este primer ejemplo es evidente la manera de paralelizar la suma de vectores\n",
      "![Alt text](imagen/suma.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Version C"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```c\n",
      "#include <stdio.h>\n",
      "\n",
      "int main(void)\n",
      "{\n",
      "int N = 10;\n",
      "float a[N],b[N],c[N];\n",
      "\n",
      "for (int i = 0; i < N; ++i){\n",
      "\ta[i] = i;\n",
      "\tb[i] = 2.0f;\t\n",
      "}\n",
      "\n",
      "for (int i = 0; i < N; ++i){\n",
      "\tc[i]= a[i]+b[i];\t\n",
      "}\n",
      "\n",
      "for (int i = 0; i < N; ++i){\n",
      "\tprintf(\"%f \\n\",c[i]);\t\n",
      "}\n",
      "\n",
      "\n",
      "return 0;\n",
      "}```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!g++ cpuAdd.c -o cpua"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat cpuAdd.c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#include <stdio.h>\r\n",
        "\r\n",
        "int main(void)\r\n",
        "{\r\n",
        "int N = 10;\r\n",
        "float a[N],b[N],c[N];\r\n",
        "\r\n",
        "for (int i = 0; i < N; ++i){\r\n",
        "\ta[i] = i;\r\n",
        "\tb[i] = 2.0f;\t\r\n",
        "}\r\n",
        "\r\n",
        "for (int i = 0; i < N; ++i){\r\n",
        "\tc[i]= a[i]+b[i];\t\r\n",
        "}\r\n",
        "\r\n",
        "for (int i = 0; i < N; ++i){\r\n",
        "\tprintf(\"%f \\n\",c[i]);\t\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "return 0;\r\n",
        "}\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!./cpua"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.000000 \r\n",
        "3.000000 \r\n",
        "4.000000 \r\n",
        "5.000000 \r\n",
        "6.000000 \r\n",
        "7.000000 \r\n",
        "8.000000 \r\n",
        "9.000000 \r\n",
        "10.000000 \r\n",
        "11.000000 \r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Version CUDA C"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![Alt text](imagen/cuda3.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![Alt text](imagen/CUDAmodelThreads.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```c\n",
      "#include <stdio.h>\n",
      "#include <cuda_runtime.h>\n",
      "// CUDA Kernel\n",
      "__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements)\n",
      "{\n",
      "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
      "    if (i < numElements)\n",
      "    {\n",
      "        C[i] = A[i] + B[i];\n",
      "    }\n",
      "}\n",
      "\n",
      "/**\n",
      " * Host main routine\n",
      " */\n",
      "int main(void)\n",
      "{\n",
      "    int numElements = 15;\n",
      "    size_t size = numElements * sizeof(float);\n",
      "    printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
      "\n",
      "    float a[numElements],b[numElements],c[numElements];\n",
      "    float *a_gpu,*b_gpu,*c_gpu;\n",
      "\n",
      "    cudaMalloc((void **)&a_gpu, size);\n",
      "    cudaMalloc((void **)&b_gpu, size);\n",
      "    cudaMalloc((void **)&c_gpu, size);\n",
      "\n",
      "    for (int i=0;i<numElements;++i ){\n",
      "    \n",
      "    \ta[i] = i*i;\n",
      "    \tb[i] = i;\n",
      "    \n",
      "    }\n",
      "    // Copy the host input vectors A and B in host memory to the device input vectors in\n",
      "    // device memory\n",
      "    printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
      "    cudaMemcpy(a_gpu, a, size, cudaMemcpyHostToDevice);\n",
      "    cudaMemcpy(b_gpu, b, size, cudaMemcpyHostToDevice);\n",
      "\n",
      "    // Launch the Vector Add CUDA Kernel\n",
      "    int threadsPerBlock = 256;\n",
      "    int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
      "    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
      "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(a_gpu, b_gpu, c_gpu, numElements);\n",
      "\n",
      "    // Copy the device result vector in device memory to the host result vector\n",
      "    // in host memory.\n",
      "    printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
      "    cudaMemcpy(c, c_gpu, size, cudaMemcpyDeviceToHost);\n",
      "\n",
      "    for (int i=0;i<numElements;++i ){\n",
      "    \tprintf(\"%f \\n\",c[i]);\n",
      "    }\n",
      "\n",
      "    // Free device global memory\n",
      "    cudaFree(a_gpu);\n",
      "    cudaFree(b_gpu);\n",
      "    cudaFree(c_gpu);\n",
      "    \n",
      "    printf(\"Done\\n\");\n",
      "    return 0;\n",
      "}\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!nvcc gpuAdd.cu -o gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!./gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Vector addition of 15 elements]\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copy input data from the host memory to the CUDA device\r\n",
        "CUDA kernel launch with 1 blocks of 256 threads\r\n",
        "Copy output data from the CUDA device to the host memory\r\n",
        "0.000000 \r\n",
        "2.000000 \r\n",
        "6.000000 \r\n",
        "12.000000 \r\n",
        "20.000000 \r\n",
        "30.000000 \r\n",
        "42.000000 \r\n",
        "56.000000 \r\n",
        "72.000000 \r\n",
        "90.000000 \r\n",
        "110.000000 \r\n",
        "132.000000 \r\n",
        "156.000000 \r\n",
        "182.000000 \r\n",
        "210.000000 \r\n",
        "Done\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!nvidia-smi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wed Oct  8 13:24:19 2014       \r\n",
        "+------------------------------------------------------+                       \r\n",
        "| NVIDIA-SMI 5.319.37   Driver Version: 319.37         |                       \r\n",
        "|-------------------------------+----------------------+----------------------+\r\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
        "|===============================+======================+======================|\r\n",
        "|   0  GeForce GTX 670     Off  | 0000:01:00.0     N/A |                  N/A |\r\n",
        "| 10%   45C  N/A     N/A /  N/A |      205MB /  2047MB |     N/A      Default |\r\n",
        "+-------------------------------+----------------------+----------------------+\r\n",
        "                                                                               \r\n",
        "+-----------------------------------------------------------------------------+\r\n",
        "| Compute processes:                                               GPU Memory |\r\n",
        "|  GPU       PID  Process name                                     Usage      |\r\n",
        "|=============================================================================|\r\n",
        "|    0            Not Supported                                               |\r\n",
        "+-----------------------------------------------------------------------------+\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1ra Implementaci\u00f3n de PyCUDA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pycuda import autoinit\n",
      "from pycuda import gpuarray\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aux = range(15)\n",
      "a = np.array(aux).astype(np.float32)\n",
      "b = (a*a).astype(np.float32)\n",
      "c = np.zeros(len(aux)).astype(np.float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu = gpuarray.to_gpu(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b_gpu = gpuarray.to_gpu(b)\n",
      "c_gpu = gpuarray.to_gpu(c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aux_gpu = a_gpu+b_gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aux_gpu.gpudata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "<pycuda._driver.DeviceAllocation at 0x2bbcde0>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(aux_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "pycuda.gpuarray.GPUArray"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu,b_gpu,c_gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "(array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
        "         11.,  12.,  13.,  14.], dtype=float32),\n",
        " array([   0.,    1.,    4.,    9.,   16.,   25.,   36.,   49.,   64.,\n",
        "          81.,  100.,  121.,  144.,  169.,  196.], dtype=float32),\n",
        " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "         0.,  0.], dtype=float32))"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2da Implementaci\u00f3n de PyCUDA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pycuda.elementwise import ElementwiseKernel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_gpu.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "dtype('float32')"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myCudaFunc = ElementwiseKernel(arguments = \"float *a, float *b, float *c\",\n",
      "                               operation = \"c[i] = a[i]+b[i]\",\n",
      "                               name = \"mySumK\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myCudaFunc(a_gpu,b_gpu,c_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([   0.,    2.,    6.,   12.,   20.,   30.,   42.,   56.,   72.,\n",
        "         90.,  110.,  132.,  156.,  182.,  210.], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3ra Implementaci\u00f3n de PyCUDA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pycuda.compiler import SourceModule"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cudaCode = open(\"gpuAdd.cu\",\"r\")\n",
      "myCUDACode = cudaCode.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myCode = SourceModule(myCUDACode)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importedKernel = myCode.get_function(\"vectorAdd\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0_Simple\r\n",
        "addCPU\r\n",
        "cpuAdd.c\r\n",
        "cpuAdd.c~\r\n",
        "gpuAdd\r\n",
        "gpuAdd.cu\r\n",
        "gpuAdd.cu~\r\n",
        "imagen\r\n",
        "intervalo.py\r\n",
        "intervalo.pyc\r\n",
        "License.txt\r\n",
        "Longuet-Higgins.ipynb\r\n",
        "Makefile\r\n",
        "README.md\r\n",
        "Sesion1_Introduccion_Python.ipynb\r\n",
        "Sesion1_Python.ipynb\r\n",
        "Sesion1_Python (ssdvortex-GA-990FXA-UD3's conflicted copy 2014-08-01).ipynb\r\n",
        "Sesion1_Test.ipynb\r\n",
        "Sesion2_Ejemplo_Clases.ipynb\r\n",
        "Sesion2_Intento_de_solucion_GPE.ipynb\r\n",
        "Sesi\u00f3n3.1_ExploreGPU.ipynb\r\n",
        "Sesion3_CUDA&PyCuda1st.ipynb\r\n",
        "Sesion3_PyCuda2nd.ipynb\r\n",
        "Sesion4_PyCuda3rd.ipynb\r\n",
        "Sesion5_LibreriasGPU.ipynb\r\n",
        "Some_bench.ipynb\r\n",
        "taylor.py\r\n",
        "taylor.py~\r\n",
        "taylor.pyc\r\n",
        "Untitled0.ipynb\r\n",
        "vectorAdd.cu\r\n",
        "vectorAdd.tar.gz\r\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nData = len(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nData"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "15"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nThreadsPerBlock = 256\n",
      "nBlockPerGrid = 1\n",
      "nGridsPerBlock = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_gpu.set(c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importedKernel(a_gpu.gpudata,b_gpu.gpudata,c_gpu.gpudata,block=(256,1,1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "array([   0.,    2.,    6.,   12.,   20.,   30.,   42.,   56.,   72.,\n",
        "         90.,  110.,  132.,  156.,  182.,  210.], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}